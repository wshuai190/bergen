init_args:
  _target_: models.generators.vllm.LLM
  model_name: "meta-llama/Meta-Llama-3.1-8B-Instruct"
  max_new_tokens: 512
  max_length: 100000
  quantization: "bitsandbytes"
batch_size: 12

