init_args: 
  _target_: models.generators.llm_cocom.COCOMLLM
  model_name: "cocom"
  decoder_model_name: "mistralai/Mistral-7B-Instruct-v0.2"
  compr_model_name: null
  max_new_tokens: 128
  sep: True
  compr_rate: 128
  compr_linear_type: 'concat'
  quantization: 'no'
  lora: true
batch_size: 6