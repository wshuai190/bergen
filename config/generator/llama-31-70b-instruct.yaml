init_args:
  _target_: models.generators.llm.LLM
  model_name: "meta-llama/Meta-Llama-3.1-70B-Instruct"
  max_new_tokens: 512
  max_length: null
  quantization: "no"
batch_size: 4