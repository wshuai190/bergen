retrieve_top_k: 50
rerank_top_k: 50
generation_top_k: 20
pyserini_num_threads: 2
run_name: null
dataset_folder: datasets/
index_folder: indexes/
runs_folder: runs/
experiments_folder: trec_rag_test_2024/plain
processing_num_proc: 2
retriever:
  init_args:
    _target_: models.retrievers.custom.CUSTOM
    model_name: custom_pooled_filtered
generator:
  init_args:
    _target_: models.generators.vllm.LLM
    model_name: meta-llama/Meta-Llama-3.1-8B-Instruct
    max_new_tokens: 512
    max_length: 100000
    quantization: bitsandbytes
  batch_size: 24
dataset:
  train:
    doc: null
    query: null
  dev:
    doc:
      init_args:
        _target_: modules.dataset_processor.MSMARCOV21SEG
        split: full
    query:
      init_args:
        _target_: modules.dataset_processor.TrecRAGTestQueries
        split: test
  test:
    doc: null
    query: null
prompt:
  system: 'Given the Question and Documents below, provide an answer for the Question
    that is generated using information exclusively from the Documents(some maybe
    irrelevant). Strive to generate a longer text, and ensure that your response is
    coherent, fluent and comprehensive with respect to the Question. '
  user: f"Question:\ {question} \n\nDocuments:\n{docs}"
  system_without_docs: Given the Question below, provide an answer for the Question.
    Strive to generate a longer text, and ensure that your response is coherent, fluent
    and comprehensive with respect to the Question.
  user_without_docs: f"Question:\ {question}"
  example: false
